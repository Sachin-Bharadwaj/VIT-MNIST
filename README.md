# VIT-MNIST
Trained Vision transformer from scratch on MNIST dataset. It has a depth of 4 with 8 multihead attention layers.
The figure below shows the attention map of classification token the last year
<img width="590" alt="image" src="https://github.com/Sachin-Bharadwaj/VIT-MNIST/assets/26499326/737f6882-c9ef-4b5b-a7fb-66555e3eedac">
Here are some of the examples from val set
<img width="608" alt="image" src="https://github.com/Sachin-Bharadwaj/VIT-MNIST/assets/26499326/b6045604-6aec-42d8-8f10-5c445b4f81c9">


